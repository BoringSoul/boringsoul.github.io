<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="andrew chung" /><link rel="canonical" href="https://boringsoul.github.io/middleware/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>深入理解Kafka：核心设计与实践原理 - 安崽的笔记</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u6df1\u5165\u7406\u89e3Kafka\uff1a\u6838\u5fc3\u8bbe\u8ba1\u4e0e\u5b9e\u8df5\u539f\u7406";
        var mkdocs_page_input_path = "middleware\\\u6df1\u5165\u7406\u89e3Kafka.md";
        var mkdocs_page_url = "/middleware/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/java.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> 安崽的笔记
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../../../">简介</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">消息队列</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">深入理解Kafka：核心设计与实践原理</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#kafka">第一章 初识Kafka</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#11">1.1 基本概念</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#12">1.2 安装和配置</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#13">1.3 生产和消费</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#14">1.4 服务端参数配置</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_1">第二章 生产者</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#21">2.1 客户端开发</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#211">2.1.1 拦截器</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#212">2.1.2 序列化器</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#213">2.1.3 分区器</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#214">2.1.4 消息发送</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#22">2.2 原理分析</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#221">2.2.1 整体架构</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#222">2.2.2 元数据更新</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#23">2.3 重要的生产者参数</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_2">第三章 消费者</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#31">3.1 消费者与消费组</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#32">3.2 客户端开发</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#321">3.2.1 必要的参数配置</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#322_kafkaconsumer">3.2.2 KafkaConsumer 初始化源码</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#324">3.2.4 订阅主题与分区</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#325">3.2.5 消费者拦截器</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#326">3.2.6 反序列化</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#327">3.2.7 消费消息</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#328">3.2.8 位移提交</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#329">3.2.9 控制或关闭消费</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3210">3.2.10 指定位移消费</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3211">3.2.11 再均衡</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3212">3.2.12 多线程实现</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3213">3.2.13 重要的消费者参数</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_3">第四章 主题与分区</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#41">4.1 主题的管理</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#411">4.1.1 创建主题</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#412">4.1.2 分区副本的创建</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#413">4.1.3 查看主题</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#414">4.1.4 修改主题</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#415">4.1.5 配置管理</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#416">4.1.6 主题端参数</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#417">4.1.7 删除主题</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#418_zk">4.1.8 zk 节点信息速查</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#42_kafkaadminclient">4.2 初识 KafkaAdminClient</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#421_kafka">4.2.1 Kafka 基本使用</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#422">4.2.2 主题合法性验证</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#43">4.3 分区的管理</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#431">4.3.1 优先副本的选举</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#432">4.3.2 分区重分配</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#433">4.3.3 复制限流</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#434">4.3.4 修改副本因子</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#44">4.4 如何选择合适的分区数</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#441">4.4.1 性能测试工具</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#442">4.4.2 分区数越多吞吐量就越高吗</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#443">4.4.3 分区数的上限</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#444">4.4.4 考量因素</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#5">第5章 日志存储</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#51">5.1 文件目录布局</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#52">5.2 日志格式的演变</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#521_v0">5.2.1 v0版本</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#522_v1">5.2.2 v1版本</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#523">5.2.3 消息压缩</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#524">5.2.4 变长字段</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#525_v2">5.2.5 v2版本</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#53">5.3 日志索引</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#531">5.3.1 偏移量索引</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#532">5.3.2 时间戳索引</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#54">5.4 日志清理</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#541">5.4.1 日志删除</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#542">5.4.2 日志压缩</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#55">5.5 磁盘存储</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#551">5.5.1 页缓存</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#552_io">5.5.2 磁盘 I/O 流程</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#553">5.5.3 零拷贝</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#6">第6章 深入服务端</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#61">6.1 协议设计</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#62">6.2 时间轮</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#63">6.3 延时操作</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#64">6.4 控制器</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#641">6.4.1 控制器的选举及异常恢复</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#642">6.4.2 优雅关闭</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#65">6.5 参数解密</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#651_brokerid">6.5.1 broker.id</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#652_bootstrapservers">6.5.2 bootstrap.servers</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#653">6.5.3 服务端参数列表</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#7">第7章 深入客户端</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#8">第8章 可靠性探究</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#9_kafka">第9章 Kafka应用</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#10_kafka">第10章 Kafka监控</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#11_1">第11章 高级应用</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#12_kafkaspark">第12章 Kafka与Spark的集成</a>
    </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">数据库相关</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../database/%E9%AB%98%E6%80%A7%E8%83%BDMySQL/">高性能MySQL-第三版</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">安崽的笔记</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">消息队列</li>
      <li class="breadcrumb-item active">深入理解Kafka：核心设计与实践原理</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="-kafka">笔记-深入理解Kafka: 核心设计与实践原理<a class="headerlink" href="#-kafka" title="Permanent link">&para;</a></h2>
<p>简单记下笔记</p>
<h3 id="kafka">第一章 初识Kafka<a class="headerlink" href="#kafka" title="Permanent link">&para;</a></h3>
<p>首先知道他是啥: </p>
<ul>
<li>消息系统:  就是一个消息队列系统, 作用无非就那几个-解耦, 削峰、异步, 然后再加上自己的集群特性, 做到可扩展、可恢复</li>
<li>持久化:  log文件存消息</li>
<li>流式处理平台: 提供接口来做窗口、连接、变换和聚合等等的操作</li>
</ul>
<h4 id="11">1.1 基本概念<a class="headerlink" href="#11" title="Permanent link">&para;</a></h4>
<blockquote>
<p>看下图就好: </p>
</blockquote>
<p><img alt="Kafka 基本架构图" src="../assets/img/blog16949bd6279df106.png" /></p>
<ul>
<li><em>Producer</em> : 生产者</li>
<li><em>Broker</em> : 就是 <em>Kafka Server</em></li>
<li><em>Consumer</em> : 消费者</li>
<li><em>Message.Topic</em>: 消息是按Topic去分的</li>
<li><em>Message.Topic.Partition</em> : <em>Topic</em> 划分为不同的分区存储, 分区的数量、分配规则, 能通过配置文件进行配置, 同时还能在运行时, 动态修改创建主题时的分区数量（只能增, 不能减）、分配规则</li>
<li><em>Message.Topic.Partition.Replicas</em>: 分区时有副本的, 每个分区的副本数量, 分配规则也是跟上面一样, 可以静态设置, 动态修改</li>
<li><em>AR( Assigned Replicas )</em>, <em>ISR (In-Sync Replicas)</em>, <em>OSR (Out-Sync Replicas)</em> =&gt; <em>AR</em> = <em>ISR</em> + <em>OSR</em></li>
<li>"Leader Replicas": 主副本,  负责读写</li>
<li>"Follower Replica": 从副本, 负责记录猪副本数据, 有一定滞后性</li>
<li><em>Message.Topic.Partition.Replica.LEO</em>: 该分区下一条消息待写入的 <em>Offset</em></li>
<li><em>Message.Topic.Partition.Replica.HW</em>: <em>HW - 1</em> = 消费者能消费到的最大 <em>Offset</em></li>
<li><em>Message.Topic.Partition.Log</em> : 在持久化层上可以把分区看成一个追加的 <em>Log</em> 文件</li>
<li><em>Message.Topic.Partition.Offset</em> : 指消息在分区中的一个偏移量, 且是分区中的唯一标识, 也就是 <em>Kafka</em> 是分区内有序的</li>
</ul>
<h4 id="12">1.2 安装和配置<a class="headerlink" href="#12" title="Permanent link">&para;</a></h4>
<blockquote>
<p>3.x 版本安装比较简单, <em>windows/linux</em> 版本都是直接下个包, 在本地跑脚本就好了</p>
</blockquote>
<h4 id="13">1.3 生产和消费<a class="headerlink" href="#13" title="Permanent link">&para;</a></h4>
<blockquote>
<p>这部分代码在后面的章节是会贴出来了, 这里就不再赘述了</p>
</blockquote>
<h4 id="14">1.4 服务端参数配置<a class="headerlink" href="#14" title="Permanent link">&para;</a></h4>
<blockquote>
<p>这里贴出最常见的几个参数说明一下, 配置的内容都是在 <em>config/server.properties</em> 里面, 3.x 版本的话, 如果要用 <em>kraft</em> 的话, 则看 <em>config/kraft/server.properties</em> 文件</p>
</blockquote>
<ul>
<li><em>process.roles</em> : 进程的角色列表, 逗号分割, 默认: <em>broker,controller</em></li>
<li><em>node.id</em> : 节点 <em>id</em>, 用来标识节点, 在日志可以用来排查问题</li>
<li><em>listeners</em> : <em>broker</em> 监听客户端的协议+地址+端口,格式为 : 协议://地址:端口, 协议值为: <em>PLAINTEXT, SSL, SASL_SSL</em></li>
<li><em>log.dirs</em> : 持久化目录, <em>log.dirs</em> 优先级大于 <em>log.dir</em></li>
</ul>
<h3 id="_1">第二章 生产者<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<h4 id="21">2.1 客户端开发<a class="headerlink" href="#21" title="Permanent link">&para;</a></h4>
<blockquote>
<p>这里我先贴整体的代码, 然后再细说</p>
</blockquote>
<pre><code class="language-Java">package org.example.producer;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.example.entity.UserProto;

import java.util.Properties;

public class KafkaProducerDemo {

    public static final String BROKER_LIST = &quot;localhost:19092,localhost:29092,localhost:39092&quot;;
    public static final String TOPIC = &quot;test&quot;;


    public static Properties initConfig() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaProducerSerializer.class.getName());
        props.put(ProducerConfig.CLIENT_ID_CONFIG, &quot;producer.client.id.demo&quot;);
        props.put(ProducerConfig.RETRIES_CONFIG, 10);
        props.put(ProducerConfig.ACKS_CONFIG, &quot;-1&quot;);
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, KafkaProducerInterceptor.class.getName());
        return props;
    }

    public static void main(String[] args) {
        Properties props = initConfig();
        try (KafkaProducer&lt;String, UserProto.User&gt; producer = new KafkaProducer&lt;&gt;(props)) {
            UserProto.User user = UserProto.User.newBuilder().setName(&quot;andrew&quot;).setSex(1).setCode(&quot;c1&quot;).build();
            ProducerRecord&lt;String, UserProto.User&gt; record = new ProducerRecord&lt;&gt;(TOPIC, user);
            producer.send(record);
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

    }
}
</code></pre>
<h5 id="211">2.1.1 拦截器<a class="headerlink" href="#211" title="Permanent link">&para;</a></h5>
<p><em>ProducerInterceptor</em> 接口是这样的</p>
<pre><code class="language-java">public interface ProducerInterceptor&lt;K, V&gt; extends Configurable, AutoCloseable {
    ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; var1);

    void onAcknowledgement(RecordMetadata var1, Exception var2);

    void close();
}
</code></pre>
<blockquote>
<p>拦截器的注入方式是这样的, 源码用反射<em>(getDeclaredConstructor().newInstance())</em>去实例化对象</p>
</blockquote>
<pre><code class="language-java">props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, KafkaProducerInterceptor.class.getName());
</code></pre>
<p>以 kafka-client 3.7.0 为例</p>
<p><em>onSend</em> 方法是在 <em>KafkaProducer</em> 源码 357 行执行的</p>
<pre><code class="language-java">public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) {
    ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors.onSend(record);
    return this.doSend(interceptedRecord, callback);
}
</code></pre>
<p><em>onAcknoledgement</em> 则是在 703 行触发, 就是在 <em>onComplete</em> 的时候调用</p>
<pre><code class="language-java">public void onCompletion(RecordMetadata metadata, Exception exception) {
    if (metadata == null) {
        metadata = new RecordMetadata(this.topicPartition(), -1L, -1, -1L, -1, -1);
    }

    this.interceptors.onAcknowledgement(metadata, exception);
    if (this.userCallback != null) {
        this.userCallback.onCompletion(metadata, exception);
    }

}
</code></pre>
<h5 id="212">2.1.2 序列化器<a class="headerlink" href="#212" title="Permanent link">&para;</a></h5>
<p><em>StringSerializer</em> 源码如下</p>
<pre><code class="language-java">package org.apache.kafka.common.serialization;

import java.io.UnsupportedEncodingException;
import java.nio.charset.StandardCharsets;
import java.util.Map;
import org.apache.kafka.common.errors.SerializationException;

public class StringSerializer implements Serializer&lt;String&gt; {
    private String encoding;

    public StringSerializer() {
        this.encoding = StandardCharsets.UTF_8.name();
    }

    public void configure(Map&lt;String, ?&gt; configs, boolean isKey) {
        String propertyName = isKey ? &quot;key.serializer.encoding&quot; : &quot;value.serializer.encoding&quot;;
        Object encodingValue = configs.get(propertyName);
        if (encodingValue == null) {
            encodingValue = configs.get(&quot;serializer.encoding&quot;);
        }

        if (encodingValue instanceof String) {
            this.encoding = (String)encodingValue;
        }

    }

    public byte[] serialize(String topic, String data) {
        try {
            return data == null ? null : data.getBytes(this.encoding);
        } catch (UnsupportedEncodingException var4) {
            throw new SerializationException(&quot;Error when serializing string to byte[] due to unsupported encoding &quot; + this.encoding);
        }
    }
}
</code></pre>
<p>没啥特别, 就是 <em>serialize</em> 里返回了 <em>string.getBytes()</em>
自定义的也是一样, 返回 <em>byte[]</em> 就好, 反序列化道理一样</p>
<blockquote>
<p>一般公司都是pb来弄序列化和反序列化的, 以下是我自己的demo代码, 十分简单</p>
</blockquote>
<pre><code class="language-java">package org.example.producer;

import org.apache.kafka.common.serialization.Serializer;
import org.example.entity.UserProto;

public class KafkaProducerSerializer implements Serializer&lt;UserProto.User&gt; {

    @Override
    public byte[] serialize(String s, UserProto.User user) {
        return user.toByteArray();
    }
}
</code></pre>
<h5 id="213">2.1.3 分区器<a class="headerlink" href="#213" title="Permanent link">&para;</a></h5>
<p>先看看源码定义</p>
<pre><code class="language-java">package org.apache.kafka.clients.producer;

import java.io.Closeable;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.Configurable;

public interface Partitioner extends Configurable, Closeable {
    int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);

    void close();

    /** @deprecated */
    @Deprecated
    default void onNewBatch(String topic, Cluster cluster, int prevPartition) {
    }
}
</code></pre>
<p>默认分区器 <em>DefaultPartioner</em> 源码是这样的</p>
<pre><code class="language-java">public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster, int numPartitions) {
    return keyBytes == null ? this.stickyPartitionCache.partition(topic, cluster) : BuiltInPartitioner.partitionForKey(keyBytes, numPartitions);
}
</code></pre>
<p>主要看key是否为空, 如果空的话调用 <em>stickyPartitionCache.partition</em>,  随机一个可用的分区来写入 <p>
非空就用内置分区器, 先用 <em>Utils.murmur2</em> 来 <em>hash</em>,  最后 % <em>numPartitions</em></p>
<h5 id="214">2.1.4 消息发送<a class="headerlink" href="#214" title="Permanent link">&para;</a></h5>
<p>发送模式有三种: 发后即忘(<em>fire-and-forget</em>)、 同步 (<em>sync</em>)、 异步(<em>async</em>), 其实 <em>send</em> 返回的是 <em>Future</em> 对象, 所以传参肯定有 <em>Callback</em> 的入参, 要同步模式的话, 直接 <em>Future.get</em> 即可。
这里讲讲增加可靠性的套路</p>
<blockquote>
<p>注意:  提高可靠性会导致性能下降</p>
</blockquote>
<pre><code class="language-java">props.put(ProducerConfig.RETRIES_CONFIG, 10); // 增加重试次数
props.put(ProducerConfig.ACKS_CONFIG, -1); //  确保所有副本有响应了才当成功
</code></pre>
<h4 id="22">2.2 原理分析<a class="headerlink" href="#22" title="Permanent link">&para;</a></h4>
<h5 id="221">2.2.1 整体架构<a class="headerlink" href="#221" title="Permanent link">&para;</a></h5>
<blockquote>
<p>完整的发送流程图如下:</p>
</blockquote>
<p><img alt="Kafka 生产者发送流程图" src="../assets/img/%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" /></p>
<blockquote>
<p>整体流程分两个线程完成, 一个主线程, 一个发送线程, 1-5 主线程完成 </p>
</blockquote>
<ol>
<li>主线程通过 <em>KafkaProducer</em> 创建消息</li>
<li>看客户端有没有实现 <em>ProducerIntercepter</em> 这个接口, 如果有就对消息进行拦截处理, 一般拦截是为了对消息做简单处理, 因为太复杂会影响发送速度, 同时这玩意是可以链式编程的, 里面的 <em>onSend()</em> 在发送前触发, <em>onAcknowleagement()</em> 在 <em>Selector</em> 返回 <em>Response</em> 后马上触发？</li>
<li>对消息的 <em>key</em>, <em>value</em> 进行序列化操作, 要自定义, 就实现 <em>org.apache.kafka.common.serlization.Seralizer</em> 接口,  <em>configure()</em> 配置当前类, 
<em>serialize(String topic, T data)</em> 就是序列化方法, 返回 <em>byte[]</em>, <em>close()</em> 用来关闭序列化器</li>
<li>知道 <em>Topic</em> 了, 就得知道消息往哪个分区发了, 如果没有自定义分区器, 那么就用默认方法来确定发送的分区, 如果有就根据自定义的结果确定分区号</li>
<li>主线程把消息缓存到对应的 <em>RecordAccumulator</em> 中,  数据结构是 <em>Map&lt;Partiion, Deque\<ProducerBatch\>></em> , <em>buffer.memory</em> 控制大小, 消息太多会阻塞发送方法,  <em>max.block.ms</em> 控制阻塞等待时间, <em>batch.size</em> 控制 <em>ProducerBatch</em> 大小</li>
<li><em>Sender</em> 线程创建 <em>Sender</em> 对象, 把 <em>RecordAccumulator</em>.<em>Map&lt;Partiion, Deque\<ProducerBatch\>></em> 转换成 <em>Map&lt;Node, List\<ProducerBatch\>></em>, 最后封成 <em><Node, Request></em> 对象</li>
<li><em><Node, Request></em> 转成 <em>Map&lt;NodeId, Deque\<Request\>></em> 放到 <em>InFlightRequests</em> 中, 这玩意是用来记录发了, 但没有响应的 <em>Request</em>,  <em>max.in.flight.requests.per.connection</em> 默认为5, 表示每个连接最大等待响应的请求数是5, 超过5就不能发送了。还能根据 <em>Deque<Request>.size()</em> 来判断每个 <em>Node</em> 的负载情况</li>
</ol>
<h5 id="222">2.2.2 元数据更新<a class="headerlink" href="#222" title="Permanent link">&para;</a></h5>
<blockquote>
<p>元数据指的是各个节点的基本信息, 包括节点地址、节点主题、节点的分区、分区 <em>leader/follower</em> 副本信息, <em>AR/ISR</em>, <em>Controller</em> 节点</p>
</blockquote>
<p>上述的元数据是通过 <em>Sender</em> 线程来更新的, 更新步骤如下
1. 找出 <em>leastLoadedNode</em> (<em>count</em> 一下 <em>InFlightRequests</em>.<em>Deque<Request>.size()</em>)
2. 发送 <em>MetadataRequest</em>, 然后缓存到 <em>InFlightRequests</em></p>
<h4 id="23">2.3 重要的生产者参数<a class="headerlink" href="#23" title="Permanent link">&para;</a></h4>
<blockquote>
<p>这些参数都是在创建 <em>Producer</em> 的时候放到 <em>props</em> 里面的</p>
</blockquote>
<ul>
<li><em>ack</em>: <p> 
        = 1 表示 <em>leader</em> 副本成功写入, 就会收到来自服务端的写入成功响应, 数据有可能会丢 <p>
        = 0 表示不用等服务端任何响应。速度最快是它了, 但它最容易丢数据 <p>
        =-1 表示所有 <em>ISR</em> 成功写入才返回成功, 最大可靠性是它了</li>
<li><em>max.request.size</em>: 客户端能发送消息的最大值, 默认 1048576<em>B</em>=1<em>M</em>, 必须 <em>&lt;= broker</em>.<em>message.max.size</em></li>
<li><em>retries</em>: 生产者重试次数</li>
<li><em>retry.backoff.ms</em> : 重试之间的间隔, 默认 100</li>
<li><em>compression.type</em>: 消息压缩方式, 默认 <em>none</em>, 可以为 <em>gzip</em> <em>snappy</em> <em>lz4</em></li>
<li><em>connections.max.idle.ms</em>: 每个限制连接最大存活时间</li>
<li><em>linger.ms</em>: 发送 <em>ProducerBacth</em> 之前等待更多消息的时间, 用来控制吞吐量的</li>
<li><em>recieve.buffer.byte</em>: 控制 <em>Socket</em> 接收缓冲区的大小, 默认值是 32768(<em>B</em>)=32<em>KB</em></li>
<li><em>send.buffer.byte</em>: 控制 <em>Socket</em> 发送缓冲区的大小, 默认值是 131072(<em>B</em>)=128<em>KB</em></li>
</ul>
<h3 id="_2">第三章 消费者<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<h4 id="31">3.1 消费者与消费组<a class="headerlink" href="#31" title="Permanent link">&para;</a></h4>
<blockquote>
<p>看下图就知道大概意思了</p>
</blockquote>
<p><img alt="消费者与消费组消费某个Topic的消息" src="../assets/img/3.1.png" /></p>
<p>消费者与消费组、分区的关系就以下几点: </p>
<ol>
<li>消费者是以分区为单位进行消费</li>
<li>同一 <em>Topic</em> 下的消费组, 里面的消费者会均摊 <em>Topic</em> 内的 <em>partition</em>, 所以可能会出现 <em>partition</em> 不够分的情况</li>
<li>消费组内的消费者, 在消费同一 <em>topic</em> 下的消息, 显然只会消费一次, 相当于 <em>p2p</em> 模式</li>
<li>如果是不同组的消费者, 就相当于广播模式了</li>
</ol>
<h4 id="32">3.2 客户端开发<a class="headerlink" href="#32" title="Permanent link">&para;</a></h4>
<blockquote>
<p>老规矩, 先把抄的代码贴出来</p>
</blockquote>
<pre><code class="language-java">package org.example.consumer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.example.entity.UserProto;

import java.time.Duration;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicBoolean;

public class KafkaConsumerDemo {

    public static final String BROKER_LIST = &quot;localhost:19092,localhost:29092,localhost:39092&quot;;
    public static final String TOPIC = &quot;test&quot;;

    private static final String GROUP_ID = &quot;group.demo&quot;;

    public static final AtomicBoolean IS_RUNNING = new AtomicBoolean(true);

    public static Map&lt;String, Object&gt; initConfig() {
        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaConsumerDeserializer.class.getName());
        props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;producer.client.id.demo&quot;);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);

        //额外功能
        props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, KafkaConsumerInterceptor.class.getName());
        return props;
    }

    public static void main(String[] args) {
        try (KafkaConsumer&lt;String, UserProto.User&gt; consumer = new KafkaConsumer&lt;&gt;(initConfig())) {
            consumer.subscribe(List.of(TOPIC));
            while (IS_RUNNING.get()) {
                ConsumerRecords&lt;String, UserProto.User&gt; records = consumer.poll(Duration.ofMillis(1000));
                for (ConsumerRecord&lt;String, UserProto.User&gt; record : records) {
                    System.out.printf(&quot; TOPIC = %s, partition = %s, offset = %s, key = %s, value = %s \n&quot;,
                            record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
            }
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
}

</code></pre>
<h5 id="321">3.2.1 必要的参数配置<a class="headerlink" href="#321" title="Permanent link">&para;</a></h5>
<blockquote>
<p>一般都是那几个了, 有了生产者代码的经验之后, 瞄一下就好了, 还有就是生产上最好用 <em>ConsumerConfig</em> 的枚举, 自己写容易出错</p>
</blockquote>
<ul>
<li><em>bootstrap.server</em>: 连的 <em>kafka.brokers</em> 的列表</li>
<li><em>group.id</em>: 就是消费者组 <em>id</em>, 如果是空的,  会提示 <em>To use the group management or offset commit APIs, you must provide a valid group.id in the consumer configuration.</em> ( <em>kafka-client v 3.7.0</em> )</li>
<li><em>key.deserializer</em>: <em>key</em> 的反序列化器,  跟生产者的 <em>key.serializer</em> 反过来就行</li>
<li><em>value.deserializer</em>: <em>value</em> 的反序列化器,  跟生产者的 <em>value.serializer</em> 反过来就行</li>
</ul>
<h5 id="322_kafkaconsumer">3.2.2 <em>KafkaConsumer</em> 初始化源码<a class="headerlink" href="#322_kafkaconsumer" title="Permanent link">&para;</a></h5>
<blockquote>
<p>这部分干货, 原书没有的, 我是在找拦截器触发时机的时候看源码, 觉得挺有意思的, 捞出来给大家分享</p>
</blockquote>
<p><em>KafkaConsumer</em> 这个类其实是用了代理模式生成了实际执行的 <em>KafkaConsumer</em> 对象</p>
<pre><code class="language-java">public class KafkaConsumer&lt;K, V&gt; implements Consumer&lt;K, V&gt;{
    KafkaConsumer(ConsumerConfig config, Deserializer&lt;K&gt; keyDeserializer, Deserializer&lt;V&gt; valueDeserializer) {
        this.delegate = CREATOR.create(config, keyDeserializer, valueDeserializer);
    }

    KafkaConsumer(LogContext logContext, Time time, ConsumerConfig config, Deserializer&lt;K&gt; keyDeserializer, Deserializer&lt;V&gt; valueDeserializer, KafkaClient client, SubscriptionState subscriptions, ConsumerMetadata metadata, List&lt;ConsumerPartitionAssignor&gt; assignors) {
        this.delegate = CREATOR.create(logContext, time, config, keyDeserializer, valueDeserializer, client, subscriptions, metadata, assignors);
    }
}
</code></pre>
<blockquote>
<p>里面根据 <em>group.protocol</em> 生成两种消费者对象, 一个是 <em>AsyncKafkaConsumer</em>, 一个是 <em>legacyKafkaConsumer</em></p>
</blockquote>
<pre><code class="language-java">public &lt;K, V&gt; ConsumerDelegate&lt;K, V&gt; create(ConsumerConfig config, Deserializer&lt;K&gt; keyDeserializer, Deserializer&lt;V&gt; valueDeserializer) {
        try {
            GroupProtocol groupProtocol = GroupProtocol.valueOf(config.getString(&quot;group.protocol&quot;).toUpperCase(Locale.ROOT));
            return (ConsumerDelegate)(groupProtocol == GroupProtocol.CONSUMER ? new AsyncKafkaConsumer(config, keyDeserializer, valueDeserializer) : new LegacyKafkaConsumer(config, keyDeserializer, valueDeserializer));
        } catch (KafkaException var5) {
            throw var5;
        } catch (Throwable var6) {
            throw new KafkaException(&quot;Failed to construct Kafka consumer&quot;, var6);
        }
    }
</code></pre>
<h5 id="324">3.2.4 订阅主题与分区<a class="headerlink" href="#324" title="Permanent link">&para;</a></h5>
<blockquote>
<p>这一个章节主要讲的是 <em>subsribe()</em> 和 <em>assign()</em> 方法</p>
</blockquote>
<p>主题订阅支持的模式:</p>
<ol>
<li><em>AUTO_TOPICS</em>: 全名称匹配, 但是需要传主题数组做为传参, </li>
<li><em>AUTO_PATTERN</em>: 正则匹配模式</li>
<li><em>USER_ASSIGNED</em>: 用户分配模式, 分配指定 <em>topic</em> 下的 <em>partition</em></li>
</ol>
<p>主题订阅的时候可以传入再平衡的回调方法</p>
<h5 id="325">3.2.5 消费者拦截器<a class="headerlink" href="#325" title="Permanent link">&para;</a></h5>
<blockquote>
<p>跟原书顺序不一样, 我是按照代码执行顺序来讲的</p>
<blockquote>
<p>拦截器的作用其实跟其他框架都一样, 都是给目标对象一个切面, 在触发某些事件/动作的前后插入一些自定义的方法, 先贴一下 <em>ConsumerInterceptor</em> 的接口源码</p>
</blockquote>
</blockquote>
<pre><code class="language-java">public interface ConsumerInterceptor&lt;K, V&gt; extends Configurable, AutoCloseable {
    ConsumerRecords&lt;K, V&gt; onConsume(ConsumerRecords&lt;K, V&gt; var1);

    void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; var1);

    void close();
}
</code></pre>
<blockquote>
<p><em>OnConsume</em> 方法触发时机在 <em>AsyncKafkaConsumer.poll()/LegacyKafakConsumer.poll()</em> 中, 当执行了 <em>pollForFethces</em> 之后会返回 <em>fetch</em> 接着就执行 <em>onConsume(fetch.records())</em></p>
</blockquote>
<p>例子</p>
<pre><code class="language-java">package org.example.consumer;

import org.apache.kafka.clients.consumer.ConsumerInterceptor;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.common.TopicPartition;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class KafkaConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; {

    private static final long EXPIRE_INTERVAL = 10 * 1000;

    @Override
    public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) {
        long now = System.currentTimeMillis();
        Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;String, String&gt;&gt;&gt; newRecords = new HashMap&lt;&gt;();
        for (TopicPartition tp : records.partitions()) {
            List&lt;ConsumerRecord&lt;String, String&gt;&gt; list = records.records(tp);
            List&lt;ConsumerRecord&lt;String, String&gt;&gt; filter = new ArrayList&lt;&gt;();
            for (ConsumerRecord&lt;String, String&gt; i : list) {
                if(now - i.timestamp() &lt;  EXPIRE_INTERVAL){
                    filter.add(i);
                }
            }
            newRecords.put(tp, filter);
        }
        return new ConsumerRecords&lt;&gt;(newRecords);
    }

    @Override
    public void close() {

    }

    @Override
    public void onCommit(Map map) {

    }

    /**
     * configure不是直接继承自Interceptor的
     *
     * @param map 配置map
     */
    @Override
    public void configure(Map&lt;String, ?&gt; map) {

    }
}
</code></pre>
<h5 id="326">3.2.6 反序列化<a class="headerlink" href="#326" title="Permanent link">&para;</a></h5>
<blockquote>
<p>反序列化的话只需要继承 <em>Deserializer</em> 的 <em>deserialize(String topic, byte[] data)</em> 方法即可
一般生产都是用 <em>ProtocalBuffer</em> 去做序列化和反序列化的, 最简单的 <em>demo</em> 如下</p>
</blockquote>
<pre><code class="language-java">package org.example.consumer;

import com.google.protobuf.InvalidProtocolBufferException;
import org.apache.kafka.common.serialization.Deserializer;
import org.example.entity.UserProto;

public class KafkaConsumerDeserializer implements Deserializer&lt;UserProto.User&gt; {

    @Override
    public UserProto.User deserialize(String topic, byte[] data) {
        try {
            return UserProto.User.parseFrom(data);
        } catch (InvalidProtocolBufferException e) {
            throw new RuntimeException(e);
        }
    }
}
</code></pre>
<h5 id="327">3.2.7 消费消息<a class="headerlink" href="#327" title="Permanent link">&para;</a></h5>
<blockquote>
<p>这一节主要讲的是 <em>poll</em> 方法</p>
</blockquote>
<p>这个 <em>poll()</em> 方法是个轮训方法, 传参 <em>Duration</em> 是指拉去线程的最大阻塞时间(因为没有消息可能得等嘛) <p>
然后返回的 ConsumerRecords 对象呢是可以迭代的</p>
<h5 id="328">3.2.8 位移提交<a class="headerlink" href="#328" title="Permanent link">&para;</a></h5>
<blockquote>
<p>这一节主要讲的是各个 <em>offset</em> 的区别以及提交 <em>offset</em> 的一些技巧</p>
</blockquote>
<p>消费者在完成消费之后其实是需要提交 <em>offset</em> (告诉 <em>broker</em> 消费到哪里了) <p></p>
<p><em>offset</em> 有三个概念 <p></p>
<p><em>consumed offset</em> = <em>last consumed offset</em> = <em>position()</em> =  <em>commited offset</em>  - 1 <p></p>
<p>每次提交的都是下个消费的 <em>offset</em> <p></p>
<p>其实无论怎么提交位移量, 都存在着重复消费和消息丢失的风险 <p></p>
<p><em>commit</em> 分 <em>sync</em> 和 <em>async</em>,  <em>async</em> 时有个回调方法, 是在 <em>commit</em> 完成后触发, 生产一般用于更改缓存/数据库中对应数据状态 <p></p>
<p>降低上面两个风险的做法就是 <p></p>
<ol>
<li>自己手动提交,  enable.auto.commit = false</li>
<li>提交 <em>offset</em> 需要有重试机制（可以在 <em>finally</em> 块中使用同步提交）, 防止提交失败 （但会有重复消费的风险）</li>
<li>自己做幂等性处理, 即使重复消费也不慌</li>
</ol>
<h5 id="329">3.2.9 控制或关闭消费<a class="headerlink" href="#329" title="Permanent link">&para;</a></h5>
<blockquote>
<p>其实就是讲了 <em>pause()</em> / <em>resume()</em> / <em>close()</em> / <em>wakeup()</em> 方法</p>
</blockquote>
<ol>
<li>
<p>因为 <em>idea</em> 会提示创建 <em>KafkaConsumer</em> 实例建议用 <em>try(resource)</em> 创建, 所以可以优雅关闭 <em>consumer</em> <p></p>
</li>
<li>
<p>因为示例代码中的无限循环的判断条件是 <em>running.get()</em>, 所以也可以优雅退出循环</p>
</li>
<li>
<p><em>wakeup()</em> 是通过抛出异常( <em>WakeupException</em> )来中断消费的, 所以要注意</p>
</li>
</ol>
<h5 id="3210">3.2.10 指定位移消费<a class="headerlink" href="#3210" title="Permanent link">&para;</a></h5>
<blockquote>
<p><em>auto.offset.reset</em> 粗粒度控制消费起始位置, <em>consumer.seek()</em></p>
</blockquote>
<ol>
<li>
<p><em>seek()</em> 方法可以指定从某个主题下的某个分区的 <em>offfset</em> 进行消费, 如果找不到位移, 就触发 <em>auto.offset.reset</em> </p>
</li>
<li>
<p><em>auto.offset.reset</em> = <em>earliest</em>/<em>latest</em>/<em>none</em> <p></p>
</li>
</ol>
<p><em>earliest</em> 从 0 开始消费
<em>latest</em> 从分区末尾开始消费
<em>none</em> 找不到消费位移的时候就抛异常</p>
<ol>
<li>
<p>可以通过 <em>beginOffsets()</em> / <em>endOffsets()</em> / <em>seekToBegin()</em> / <em>seekToEnd()</em> 找到头尾位置进行消费</p>
</li>
<li>
<p>可通过 <em>consuemr.offsetForTimess( Map<TopciPartition, Long> )</em> 查找对应的 <em>offset</em>, 然后通过 <em>seek()</em> 定位消费</p>
</li>
</ol>
<h5 id="3211">3.2.11 再均衡<a class="headerlink" href="#3211" title="Permanent link">&para;</a></h5>
<blockquote>
<p>指的是分区所属权从一个消费者转移到另一个消费者的行为, 其实就是发生在消费者组发生变化的时候（组内成员有增减）, 应该怎么处理</p>
</blockquote>
<ol>
<li>再均衡发生期间, 相关的消费者是无法消费的（即对应消费者组内的消费者不可用）</li>
<li>分区重分配的时候, 当前消费者的状态会丢失, 其实就是<em>A</em>消费到一半的时候, 分区又给<em>B</em>消费, 如果消费位移没提交, 就可能重复消费</li>
<li>
<p>再均衡监听器有两个方法来规避这种问题 <p>
   1) <em>onPartitionsRevoke(Collcetion<TopciPartition>)</em> <p></p>
<p>消费者停止消费后, 重分配之前触发 (这里提交已消费完的 <em>offset</em>, 本地保存)</p>
</li>
</ol>
<p>2) <em>onPartitionsAssigned(partitions)</em> <p></p>
<pre><code>   重分配之后, 消费者开始消费之前触发 (本地保存的 *offset* 找出来, 再 *seek* )
</code></pre>
<h5 id="3212">3.2.12 多线程实现<a class="headerlink" href="#3212" title="Permanent link">&para;</a></h5>
<blockquote>
<p><em>KafkaProducer</em> 是线程安全的, <em>KafkaConsumer</em> 是线程不安全的, 这一节主要讲消费者如何多线程消费</p>
<p>注意, 如果生产中对消息的顺序性有要求, 不建议使用多线程消费同一分区的数据, 因为还得自己维护数据的有序性</p>
</blockquote>
<p>实现方式分以下几种</p>
<ol>
<li>线程封闭, 实例化多个 <em>Consumer</em> 对象进行消费</li>
<li>多线程消费同一个分区（不推荐）</li>
<li>包装 <em>ThreadPool</em> 和 <em>Consumer</em>, 把 <em>poll()</em> 到的 <em>Record</em> 扔到 <em>ThreadPool</em> 里面, 就是一个 <em>Consumer</em> 拉取某个主题, 多线程消费</li>
</ol>
<p>第三个方案需要注意的是 <em>offset</em> 提交问题, 可以用滑窗/<em>AQS</em>去解决这个问题</p>
<h5 id="3213">3.2.13 重要的消费者参数<a class="headerlink" href="#3213" title="Permanent link">&para;</a></h5>
<ol>
<li><em>fetch.min.bytes</em> = 每次拉取最小数据量, 控制吞吐用的</li>
<li><em>fetch.max.bytes</em> = 每次拉取最大数据量, 消息大于该值也不会导致消息不可读</li>
<li><em>fetch.max.wait.ms</em> = 每次拉取最大等待时间, 也是控制吞吐, 具体看实际应用场景</li>
<li><em>max.partition.fetch.bytes</em> = 每个分区每次返回给 <em>Consumer</em> 的最大数据量, 指的是 <em>fetch.bytes / partition_num</em></li>
<li><em>max.poll.record</em> = 拉取最大消息数, 默认500条</li>
<li><em>connections.max.idle.ms</em> = 多久之后关闭限制连接, 默认 540000 <em>ms</em>, 就是 9 <em>min</em></li>
<li><em>exclude.internal.topics</em> = 是否屏蔽内部主题, 默认是 <em>true</em>, 表示不能用正则去订阅主题, <em>false</em> 则相反</li>
<li><em>receives.buffer.bytes</em> = 接收缓冲区大小, 默认 65536 <em>B</em>, 就是 64 <em>KB</em></li>
<li><em>send.buffer.size</em> = 发送缓冲区大小, 默认 131072 <em>B</em>, 就是 128 <em>KB</em></li>
<li><em>request.timeout.ms</em> = 等待请求响应的最长时间, 默认 30000 <em>ms</em></li>
<li><em>metadata.max.age.ms</em> = 等待请求响应的最长时间, 默认 30000 <em>ms</em></li>
<li><em>reconnect.backoff.ms</em> = 等待请求响应的最长时间, 默认 30000 <em>ms</em></li>
<li><em>retry.backo ms</em> = 等待请求响应的最长时间, 默认 30000 <em>ms</em></li>
<li><em>isolation.level</em> = 事务隔离等级, <em>value = "read_uncommitted/read_commiitted"</em>, 默认是 <em>read_uncommitted</em>, 可以消费到 <em>HW</em></li>
</ol>
<h3 id="_3">第四章 主题与分区<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<h4 id="41">4.1 主题的管理<a class="headerlink" href="#41" title="Permanent link">&para;</a></h4>
<blockquote>
<p>主题管理可以用 <em>kafka-topics.sh(bat)</em> 来管理, 当然还能用 <em>KafkaAdminClient</em> 来实现。</p>
</blockquote>
<h5 id="411">4.1.1 创建主题<a class="headerlink" href="#411" title="Permanent link">&para;</a></h5>
<ol>
<li>如果 <em>auto.create.otpics.enable</em> = <em>true</em>, 客户端(生产者/消费者)会在没有创建对应主题的下, 根据 <em>num.partitions</em> 和 <em>default.replication.facotr</em> 来创建主题, 命令如下 <p></li>
</ol>
<pre><code class="language-shell">kafka-topics.sh --zookeeper &lt;String : hosts&gt; -create topic [String: topic] --partitions &lt;分区数量&gt; replication-factor &lt;副本数量&gt; 
</code></pre>
<ol>
<li><em>replica-assignment</em> 命令, 还能指定副本分配</li>
</ol>
<pre><code class="language-shell">## 假如 partition_num = 3, replica_nums = 2,  格式如下,  第一个是 *part1* 所在的 *broker*,  以此类推
--replica-assignment &lt;brokerId1:brokerId2, brokerId2:brokerId3, brokerId3:brokerId1......&gt; 
</code></pre>
<blockquote>
<p>分区同一 <em>part</em> 必须放在不同 <em>broker</em> 中, 否则会报异常</p>
</blockquote>
<ol>
<li><em>--config</em> 为指定 <em>topic</em> 设置参数</li>
</ol>
<pre><code class="language-shell">--config &lt;key=value&gt; --config &lt;key=value&gt;...
</code></pre>
<ol>
<li>
<p>建完主题后, 它会在 <em>dir.logs</em>/<em>dir.log</em> 创下对应的主题和分区, 一般命名格式为 <em>\&lt;topic&gt;-\&lt;partition&gt;</em></p>
</li>
<li>
<p><em>topic</em> 具有唯一性</p>
</li>
<li>
<p>获取元数据信息就能知道主题、分区、配置情况, 如果是连了 <em>zookeeper</em> 的话, 则可以看节点信息获取这些情况</p>
</li>
</ol>
<h5 id="412">4.1.2 分区副本的创建<a class="headerlink" href="#412" title="Permanent link">&para;</a></h5>
<p>自动创建的原理</p>
<ol>
<li>轮询 <em>partition</em>,  然后每次先随机个 <em>startIndex</em>, <em>nextReplicaShift</em></li>
<li><em>startIndex</em> 算出第一个副本索引 <em>firstReplicaIndex</em>, 然后 brokerIds[index] 就是副本落到的broker了</li>
<li><em>fristReplicaIndex</em>, <em>nextReplicaShift</em> 作为传参, 又传到函数 <em>prelicaIndex</em> 里面, 得到第二个 <em>index</em></li>
<li>循环操作</li>
</ol>
<h5 id="413">4.1.3 查看主题<a class="headerlink" href="#413" title="Permanent link">&para;</a></h5>
<blockquote>
<p>describe 指令查看主题信息, 可额外增加 <em>topics-with-overrides</em>(覆盖默认配置的主题), <em>under-replicated-partitions</em>(查找失效副本), <em>unavailable-partitions</em>(查找不可用副本)</p>
</blockquote>
<h5 id="414">4.1.4 修改主题<a class="headerlink" href="#414" title="Permanent link">&para;</a></h5>
<blockquote>
<p>基本用 <em>kafka-configs.sh</em> 中的 <em>alert</em> 方法来修改主题, 不支持减少分区</p>
</blockquote>
<h5 id="415">4.1.5 配置管理<a class="headerlink" href="#415" title="Permanent link">&para;</a></h5>
<blockquote>
<p>基本讲 <em>kafka-configs.sh</em> 脚本的用法</p>
</blockquote>
<p><em>example</em> : 删除某个 <em>topic</em> 下的配置</p>
<pre><code class="language-shell">kafka-configs.sh --zookeeper &lt;zk地址&gt; --alter --entity-type topics --entity-name topic-config --delete-config
cleanup.policy,max.message.bytes
</code></pre>
<h5 id="416">4.1.6 主题端参数<a class="headerlink" href="#416" title="Permanent link">&para;</a></h5>
<p>格式: 主题端参数 - 对应 <em>broker</em> 的参数 = 释义</p>
<p>cleanup.policy - log.cleanup.policy = 日志压缩策略, 默认 <em>delete</em>, 可为 <em>compact</em> <p>
compression.type - compression.type = 压缩类型, 默认 <em>producer</em>, 保留为生产者使用的原始压缩, 可为 <em>uncompressed/snappy/gzip/lz4</em> <p>
delete.retention.ms - log.cleaner.delete.retention.ms = 标记为删除的数据保留的时间, 默认86400000, 就是一天 <p>
file.delete.delay.ms - log.segment.delete.delay.ms = 清理文件前等待的时间, 默认60000, 即1分钟 <p>
flush.message - log.flush.interval.messages = 需要收集多少数据才强制刷盘, 默认由操作系统决定, 不建议更改, 值为 <em>Long.MAX_VALUE</em> <p>
flush.ms - log.flush.interval.ms = 需要等待多久才强制落盘, 默认也是操作系统决定 <p>
follower.replication.throttled - follower.replication.throttled = 配置被限制速率的主题所以对应的 <em>follower</em> 副本列表 <p>
index.interval.bytes - log.index.interval.bytes = 控制添加索引的频率, 默认 4096, 消息字节数超过这个值就会创建索引 <p>
leader.replication.throttled - leader.replication.throttled = 配置被限制速率的主题所以对应的 <em>leader</em> 副本列表
.....</p>
<h5 id="417">4.1.7 删除主题<a class="headerlink" href="#417" title="Permanent link">&para;</a></h5>
<p><em>kafka-topics.sh</em> 脚本操作的话就是这样的</p>
<pre><code class="language-shell">kafka-topics.sh --zookeeper &lt;zk地址&gt; --delete --topic topic-delete
</code></pre>
<p><em>zkCli.sh</em> 操作是这样的</p>
<pre><code class="language-shell">
rmr /config/topics/&lt;topic-name&gt;
delete /brokers/topics/&lt;topic-name&gt;
</code></pre>
<h5 id="418_zk">4.1.8 <em>zk</em> 节点信息速查<a class="headerlink" href="#418_zk" title="Permanent link">&para;</a></h5>
<p><em>/brokers/topics/<topic-name></em> : <em>brokers</em> 中的创建的 <em>topics</em>
<em>/config/topics/[topic名]</em> : 查看指定 <em>topic</em> 的设置</p>
<h4 id="42_kafkaadminclient">4.2 初识 <em>KafkaAdminClient</em><a class="headerlink" href="#42_kafkaadminclient" title="Permanent link">&para;</a></h4>
<h5 id="421_kafka">4.2.1 Kafka 基本使用<a class="headerlink" href="#421_kafka" title="Permanent link">&para;</a></h5>
<p>基本功能如下</p>
<ol>
<li>创建主题: CreateTopicsResult createTopics(Collection<NewTopic> topics)</li>
<li>删除主题: DeleteTopicsResult deleteTopics(Collection<String> topics)</li>
<li>列出所有可用的主题: ListTopicsResult listTopics()</li>
<li>查看主题信息: DescribeConfigsResult describeTopics(Collection<STring> topicNames)</li>
<li>查询配置信息: DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources)</li>
<li>修改配置信息: AlertConfigsResult alterConfigs(Map<ConfigResource, Config> configs)</li>
<li>增加分区: CreatePartitionsResult createPartitions(Map<String, NewPartitions> newPartitions)</li>
</ol>
<blockquote>
<p>演示代码如下</p>
</blockquote>
<pre><code class="language-java">package org.example.admin;

import org.apache.kafka.clients.admin.*;
import org.apache.kafka.common.config.ConfigResource;

import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class MyAdminClient {

    private static final String BROKER_LIST = &quot;localhost:19092&quot;;
    private static final String TOPIC = &quot;DELETE_TOPIC&quot;;

    private static final String DELETE_TOPIC = &quot;topic-demo&quot;;


    public static void main(String[] args) {
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        map.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);
        map.put(AdminClientConfig.CLIENT_ID_CONFIG, &quot;admin.client&quot;);
        try (AdminClient client = AdminClient.create(map)) {
            createTopic(client);
            listAllTopics(client);
            deleteTopic(client);
            describeConfig(client);
            alterConfig(client);
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }

    private static void listAllTopics(AdminClient client) throws Exception {
        ListTopicsResult result = client.listTopics();
        for (TopicListing tl : result.listings().get()) {
            System.out.println(tl.toString());
        }
    }

    private static void createTopic(AdminClient adminClient) throws Exception {
        adminClient.createTopics(List.of(new NewTopic(TOPIC, 3, (short) 3))).all().get();
    }

    private static void deleteTopic(AdminClient adminClient) throws Exception {
        adminClient.deleteTopics(List.of(DELETE_TOPIC)).all().get();
    }

    private static void describeConfig(AdminClient adminClient) throws Exception {
        ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, TOPIC);
        System.out.println(adminClient.describeConfigs(List.of(resource)).all().get().get(resource));
    }

    private static void alterConfig(AdminClient adminClient) throws Exception {
        ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, TOPIC);
        ConfigEntry entry = new ConfigEntry(&quot;cleanup.policy&quot;, &quot;compact&quot;);
        AlterConfigOp config = new AlterConfigOp(entry, AlterConfigOp.OpType.SET);
        Map&lt;ConfigResource, Collection&lt;AlterConfigOp&gt;&gt; configs = new HashMap&lt;&gt;();
        configs.put(resource, List.of(config));
        System.out.println(adminClient.incrementalAlterConfigs(configs).all().get());
    }

}

</code></pre>
<h5 id="422">4.2.2 主题合法性验证<a class="headerlink" href="#422" title="Permanent link">&para;</a></h5>
<ol>
<li>生产环境中的 <em>auto.create.topics.enable</em> 一般是 <em>false</em>, 所以只能用脚本或者 <em>KafkaAdmin</em> 创建主题</li>
<li>校验合法性的关键参数是 <em>create.topic.policy.class.name</em>, 默认为 <em>null</em>, 然后自己实现 <em>org.apache.kafka.server.policy.CreateTopicPolicy</em> 接口就行, 最后在 <em>config/server.properties</em> 配好这个配置就行</li>
<li>主题合法性校验一般是校验创建的主题中其他参数如 <em>partition</em>/<em>replicas-num</em> 等等, 反正这个接口入参是 <em>metadata</em> 来的, 拿出来用就得了</li>
</ol>
<h4 id="43">4.3 分区的管理<a class="headerlink" href="#43" title="Permanent link">&para;</a></h4>
<h5 id="431">4.3.1 优先副本的选举<a class="headerlink" href="#431" title="Permanent link">&para;</a></h5>
<p>使用场景: 在 <em>leader</em> 挂掉之后, 可能需要执行的操作 <p></p>
<p>目的: 为了防止 <em>broker</em> 集群负载失衡 <p></p>
<p>具体做法: <p>
1. 利用 <em>auto.leader.rebalance.enable=true</em>, <em>Kafka</em> 控制器会创建定时器来计算不平衡率, 如果超过 <em>leader.imbalance.per.broker.percentage</em>, 就会自动执行有限副本的选举, 执行周期为 <em>leader.imbalance.checke.ientrval.seconds</em> (默认300s), 缺点是不可控, 也有可能会有性能问题, 引起客户端阻塞
2. 利用 <em>kafka-perferred-replica-election.sh</em> 来手动执行, 如果分区数目多, 性能有影响
3. 利用 <em>json</em> 文件来对部分主题下的部分分区执行副本优先选举的操作</p>
<h5 id="432">4.3.2 分区重分配<a class="headerlink" href="#432" title="Permanent link">&para;</a></h5>
<p>使用场景: 新加入的 <em>broker</em> 不会分配旧分区, 只能分配新主题的分区, 所以需要重新分配分区副本 <p></p>
<p>目的: 防止分区失衡 <p></p>
<p>具体做法:</p>
<ol>
<li>用 "<em>kafka-reassign-partition.sh --generate --topics-to-move-json-file 文件名 --broker-list 节点数字</em>" 这个命令来导出重分配方案, 存成json文件</li>
<li>用 "<em>kafka-reassign-partition.sh --execute --reassignment-json-file 上面的文件</em>" 这个命令来执行重分配方案, 上一步到处是方便手动更改</li>
</ol>
<h5 id="433">4.3.3 复制限流<a class="headerlink" href="#433" title="Permanent link">&para;</a></h5>
<p>发生时机: 分区重分配的时候, 就是副本在节点之间复制的时候 <p></p>
<p>目的: 降低因重分配时带来的性能削减 <p></p>
<p>具体做法:</p>
<ol>
<li>用 <em>kafka-config.sh</em> + <em>follower.replication.throttled.rate</em> 和 <em>leader.replication.throttled.rate</em> 设置, 单位是 <em>B/s</em></li>
<li>用 <em>in/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka --verify --reassignment-json-file project.json</em> 查看进度</li>
</ol>
<h5 id="434">4.3.4 修改副本因子<a class="headerlink" href="#434" title="Permanent link">&para;</a></h5>
<p>使用场景: 创建主题的时候填错副本因子数/运行后想提高可靠性以及容错性</p>
<p>具体做法:</p>
<ol>
<li>用 <em>kafka-reassign-partition.sh --generate --topics-to-move-json-file 文件名 --broker-list 节点数字</em> 来导出当前分配方案</li>
<li>文本修改, 修改的 <em>json</em> 节点是 <em>replicas</em>  以及 <em>log_dirs</em> </li>
</ol>
<h4 id="44">4.4 如何选择合适的分区数<a class="headerlink" href="#44" title="Permanent link">&para;</a></h4>
<blockquote>
<blockquote>
<p>看下面的标题就知道怎么选了</p>
</blockquote>
</blockquote>
<h5 id="441">4.4.1 性能测试工具<a class="headerlink" href="#441" title="Permanent link">&para;</a></h5>
<ol>
<li>生产者用 <em>kafka-producer-perf-test.sh  --topic topic-1 --num-records 1000000 --record-size 1024 --throughput 100 --producer-props bootstrap.servers=localhost:9092 acks=1</em> </li>
</ol>
<blockquote>
<p><em>throughput</em> = 0 不限流, 当前限流 100 <em>bytes</em></p>
</blockquote>
<ol>
<li>消费者用 <em>kafka-consumer-perf-test.sh --topic topic-1 --messages 1000000 --broker-list localhost:9092</em>, 方法跟上面一样</li>
</ol>
<h5 id="442">4.4.2 分区数越多吞吐量就越高吗<a class="headerlink" href="#442" title="Permanent link">&para;</a></h5>
<blockquote>
<p>明细不是, 会有峰值, 看图好像是 50 个分区的时候性能最佳</p>
</blockquote>
<h5 id="443">4.4.3 分区数的上限<a class="headerlink" href="#443" title="Permanent link">&para;</a></h5>
<p>跟文件描述符相关, 再多其实也没用</p>
<h5 id="444">4.4.4 考量因素<a class="headerlink" href="#444" title="Permanent link">&para;</a></h5>
<p>看菜吃饭得了, 分区可以设为节点数的倍数, 分区一来均衡, 二来可靠</p>
<h3 id="5">第5章 日志存储<a class="headerlink" href="#5" title="Permanent link">&para;</a></h3>
<h4 id="51">5.1 文件目录布局<a class="headerlink" href="#51" title="Permanent link">&para;</a></h4>
<blockquote>
<p>直接看图就得了, 根目录下的日志文件夹命名规则是 <em>\&lt;topic&gt;-\&lt;partition&gt;</em></p>
</blockquote>
<p><center></p>
<p><img alt="Kafka 日志文件目录布局" src="../assets/img/5.2.png" /></p>
<p><img alt="Kafka topic-partition布局" src="../assets/img/5.2.sub.jpg" /></p>
<p></center></p>
<h4 id="52">5.2 日志格式的演变<a class="headerlink" href="#52" title="Permanent link">&para;</a></h4>
<blockquote>
<p>朝着内容压缩, 属性扩展的方向演变</p>
</blockquote>
<h5 id="521_v0">5.2.1 v0版本<a class="headerlink" href="#521_v0" title="Permanent link">&para;</a></h5>
<blockquote>
<p>十分基础的设计, 只能说该有的都有了</p>
</blockquote>
<p><center></p>
<p><img alt="日志格式v0版本" src="../assets/img/5.2.1.jpg" /></p>
<p></center></p>
<p>大概抄一下字段的解释</p>
<ul>
<li><em>crc32</em> (4B) : crc32 校验, 校验 <em>magic - value</em></li>
<li><em>magic</em> (1B) : 消息格式版本号, <em>v0 = 0</em>, <em>v1 = 1</em>, <em>v2 = 2</em></li>
<li><em>attribute</em> (1B) : 消息属性, 低3位压缩类型: 0 没有压缩 /1 GZIP /2 SNAPPY /3 LZ4</li>
<li><em>key lenght</em> (4B) : 消息 <em>key</em> 长度, -1 表示没有 <em>key</em></li>
<li><em>key</em> : 可选字段</li>
<li><em>value length</em> (4B) : 值长度, -1 表示消息为空, 人称墓碑消息</li>
<li><em>value</em> : 消息体</li>
</ul>
<h5 id="522_v1">5.2.2 v1版本<a class="headerlink" href="#522_v1" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="日志格式v1版本" src="../assets/img/5.2.2.jpg" /></p>
<p></center></p>
<ul>
<li><em>attribute</em> (1B) : 消息属性, 低3位压缩类型: 0 没有压缩 /1 GZIP /2 SNAPPY /3 LZ4, 第四位 0 表示 <em>timestamp</em> 类型为 <em>CreateTime</em>, <em>而1表示timestamp</em> 类型为 <em>LogAppendTime</em>, 其他位保留</li>
<li><em>timestamp</em> (8B) : 时间戳, 表示哪种时间看上面的属性</li>
</ul>
<h5 id="523">5.2.3 消息压缩<a class="headerlink" href="#523" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="消息压缩" src="../assets/img/5.2.3-1.jpg" /></p>
<p></center></p>
<ul>
<li>分两层消息, 叫做外层消息和内层消息</li>
<li>外层消息的 <em>offset</em> = <em>absolute offset</em> = 内层消息的最后一条消息</li>
<li>找内层消息的 <em>absolute offset</em> 很简单, 就是外层的 <em>offset</em> 减内层的 <em>offset</em></li>
</ul>
<blockquote>
<p>压缩情况的时间戳含义又有区别, 解析如下</p>
</blockquote>
<p>外层消息的timestamp设置为: </p>
<ul>
<li>
<p>如果timestamp类型是CreateTime, 那么设置的是内层消息中最大的时间戳。</p>
</li>
<li>
<p>如果timestamp类型是LogAppendTime, 那么设置的是Kafka服务器当前的时间戳。</p>
</li>
</ul>
<p>内层消息的timestamp设置为: </p>
<ul>
<li>
<p>如果外层消息的timestamp类型是CreateTime, 那么设置的是生产者创建消息时的时间戳。</p>
</li>
<li>
<p>如果外层消息的timestamp类型是LogAppendTime, 那么所有内层消息的时间戳都会被忽略。</p>
</li>
</ul>
<h5 id="524">5.2.4 变长字段<a class="headerlink" href="#524" title="Permanent link">&para;</a></h5>
<blockquote>
<p><em>Kafka 3.x</em> 的消息格式只支持这个消息格式, 且这个版本多了 <em>Varints</em> 和 <em>ZigZag</em> 编码</p>
</blockquote>
<ul>
<li>
<p><em>ZigZag</em> 编码的算法比较简答, <em>sint32</em> 的编码 =&gt; (n &lt;&lt; 1) ^ (n &gt;&gt; 31), <em>sint64</em> 的则是 (n &lt;&lt; 1) ^ (n &gt;&gt; 63), 主要的作用是压缩负数编码长度</p>
</li>
<li>
<p><em>Varints</em> 表示方法: 每个字节都有一个位于最高位的 <em>msb</em> 位（<em>most significant bit</em>）, 除最后一个字节外, 其余 <em>msb</em> 位都设置为1, 最后一个字节的 <em>msb</em> 位为0, <em>Varints</em> 中采用的是小端字节序, 即最小的字节放在最前面, 这个表示法可能会让部分数字的编码长度变大</p>
</li>
<li>
<p>算法流程如下</p>
</li>
</ul>
<pre><code>假设为65 =&gt; 0100 0001

先 *ZigZag* =&gt; 1000 0010 ^ 0000 0000 = 1000 0010
因为低7位有效, 所以补位变成 000 0001 000 0010
低位在前, 000 0010 000 0001, 最后补个 *msb*, 变成 1000 0010 0000 0001
</code></pre>
<h5 id="525_v2">5.2.5 v2版本<a class="headerlink" href="#525_v2" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="v2版本" src="../assets/img/5.24-1.jpg" /></p>
<p>v2版本
</center></p>
<ul>
<li>
<p><em>length</em>: 消息总长度。</p>
</li>
<li>
<p><em>attributes</em>: 弃用, 但还是在消息格式中占据1B的大小, 以备未来的格式扩展。</p>
</li>
<li>
<p><em>timestamp delta</em>: 时间戳增量。通常一个 <em>timestamp</em> 需要占用8个字节, 如果像这里一样保存与 <em>RecordBatch</em> 的起始时间戳的差值, 则可以进一步节省占用的字节数。</p>
</li>
<li>
<p><em>offset delta</em>: 位移增量。保存与 <em>RecordBatch</em> 起始位移的差值, 可以节省占用的字节数。</p>
</li>
<li>
<p><em>headers</em>: 这个字段用来支持应用级别的扩展, 而不需要像 <em>v0</em> 和 <em>v1</em> 版本一样不得不将一些应用级别的属性值嵌入消息体。<em>Header</em> 的格式如图5-7最右部分所示, 包含 <em>key</em> 和 <em>value</em>, 一个 <em>Record</em> 里面可以包含0至多个 <em>Header</em>。</p>
</li>
<li>
<p><em>first offset</em>: 表示当前 <em>RecordBatch</em> 的起始位移。</p>
</li>
<li>
<p><em>length</em>: 计算从 <em>partition leader epoch</em> 字段开始到末尾的长度。</p>
</li>
<li>
<p><em>partition leader epoch</em>: 分区 <em>leader</em> 纪元, 可以看作分区 <em>leader</em> 的版本号或更新次数, 详细内容请参考8.1.4节。</p>
</li>
<li>
<p><em>magic</em>: 消息格式的版本号, 对v2版本而言, magic 等于2。</p>
</li>
<li>
<p><em>attributes</em>: 消息属性, 注意这里占用了两个字节。低3位表示压缩格式, 可以参考 <em>v0</em> 和 <em>v1</em> ；第4位表示时间戳类型；第5位表示此 <em>RecordBatch</em> 是否处于事务中, 0表示非事务, 1表示事务。第6位表示是否是控制消息（<em>ControlBatch</em>）, 0表示非控制消息, 而1表示是控制消息, 控制消息用来支持事务功能, 详细内容请参考7.4节。</p>
</li>
<li>
<p><em>last offset delta</em>: <em>RecordBatch</em> 中最后一个 <em>Record</em> 的 <em>offset</em> 与 <em>first offset</em> 的差值。主要被 <em>broker</em> 用来确保 <em>RecordBatch</em> 中 <em>Record</em> 组装的正确性。</p>
</li>
<li>
<p><em>first timestamp</em>: <em>RecordBatch</em> 中第一条 <em>Record</em> 的时间戳。</p>
</li>
<li>
<p><em>max timestamp</em>: <em>RecordBatch</em> 中最大的时间戳, 一般情况下是指最后一个 Record 的时间戳, 和 <em>last offset delta</em> 的作用一样, 用来确保消息组装的正确性。</p>
</li>
<li>
<p><em>producer id</em>: PID, 用来支持幂等和事务, 详细内容请参考7.4节。</p>
</li>
<li>
<p><em>producer epoch</em>: 和 <em>producer id</em> 一样, 用来支持幂等和事务, 详细内容请参考7.4节。</p>
</li>
<li>
<p><em>first sequence</em>: 和 <em>producer id</em>、<em>producer epoch</em> 一样, 用来支持幂等和事务, 详细内容请参考7.4节。</p>
</li>
<li>
<p><em>records count</em>: <em>RecordBatch</em> 中 <em>Record</em> 的个数。</p>
</li>
</ul>
<h4 id="53">5.3 日志索引<a class="headerlink" href="#53" title="Permanent link">&para;</a></h4>
<p>主要讲 <em>.index</em> 文件和 <em>.timeindex</em>, <em>.index</em> 文件是通过消息偏移量找消息, <em>.timeindex</em> 则是根据指定时间戳找时间</p>
<ol>
<li>首先, 每当写入的消息量 &gt; <em>log.index.interval.bytes</em>, 就会新增索引项</li>
<li>符合以下其中一个条件, 日志文件都会切分</li>
<li>日志分段文件 &gt; <em>broker</em> 中的 <em>log.segment.bytes</em> (默认1073741824, 1 <em>GB</em>)</li>
<li>系统当前时间 - 日志分段消息最大时间戳 &gt; <em>log.roll.ms/log.roll.hours</em>, 此处 <em>log.roll.ms</em> 优先级大点 (默认只设置 <em>log.roll.hours = 7</em>)</li>
<li><em>.index</em> 文件大小 or <em>.timeindex</em> 文件大小 &gt; <em>log.index.size.max.bytes</em> (默认 10485760=10 <em>MB</em>)</li>
<li>追加消息 <em>offset - baseOffset &gt; Integer.MAX</em></li>
</ol>
<h5 id="531">5.3.1 偏移量索引<a class="headerlink" href="#531" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="16进制.index文件编码" src="../assets/img/5.3.1-1.jpg" /></p>
<p>8 * 16 = 4 * 32 刚好 int32, 前8后8看就得了</p>
<p><img alt="16进制.index文件解码" src="../assets/img/5.3.1-2.jpg" /></p>
<p></center></p>
<p>前4个字节表示相对偏移量, 后4个字节表示消息在日志分段文件对应的物理位置</p>
<p>查找方法: 二分法 + 跳表</p>
<p><center></p>
<p><img alt="偏移量索引示意图" src="../assets/img/5.3.1-3.jpg" /></p>
<p>偏移量索引示意图</p>
<p><img alt="16进制.index文件解码" src="../assets/img/5.3.1-4.jpg" /></p>
<p>跳表查找偏移量所在的日志分段, 计算相对偏移量, 最后再用前面图的方法, 就可以找到消息</p>
<p></center></p>
<h5 id="532">5.3.2 时间戳索引<a class="headerlink" href="#532" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="时间戳索引格式" src="../assets/img/5.3.2.jpg" /></p>
<p>64字节 +  32字节</p>
<p><img alt="查找方式" src="../assets/img/5.3.2-2.jpg" /></p>
<p></center></p>
<ol>
<li>
<p>将 targetTimeStamp 和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段。日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间。</p>
</li>
<li>
<p>找到相应的日志分段之后，在时间戳索引文件中使用二分查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283，28]，如此便找到了一个相对偏移量28。</p>
</li>
<li>
<p>在偏移量索引文件中使用二分算法查找到不大于28的最大索引项，即[26，838]。</p>
</li>
<li>
<p>从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息。</p>
</li>
</ol>
<h4 id="54">5.4 日志清理<a class="headerlink" href="#54" title="Permanent link">&para;</a></h4>
<p>日志清理策略有2, 日志删除和日志压缩, 通过 <em>log.cleanup.policy</em> 进行设置, 默认是 <em>delete</em>, 可以同时支持两种策略。删除策略是根据一定规则去删数据, 而压缩则是同一个 <em>key</em> 下保留最新值</p>
<h5 id="541">5.4.1 日志删除<a class="headerlink" href="#541" title="Permanent link">&para;</a></h5>
<ol>
<li>基于时间: 通过broker端参数 <em>log.retention.hours</em>、<em>log.retention.minutes</em> 和 <em>log.retention.ms</em> 来配置, 优先级粒度越小越大, 默认值 7 天, 只设置小时</li>
<li>基于日志大小: 根据 <em>log.retention.bytes</em> 进行设置, 指的是总大小, 默认 1073741824，即 <em>1GB</em></li>
<li>基于日志起始偏移量: 通过 <em>DeleteRecordsRequest</em> 请求, 然后判断日志分段的起始偏移量是否小于 <em>logStartOffset</em></li>
</ol>
<h5 id="542">5.4.2 日志压缩<a class="headerlink" href="#542" title="Permanent link">&para;</a></h5>
<ol>
<li>日志压缩跟 <em>Redis</em> 的 <em>RDB</em> 模式有点像, 可以提高起始加载的速度</li>
<li><em>clener-offset-checkpoint</em> 文件会把 <em>log</em> 文件分为 <em>clean</em> 和 <em>dirty</em> 两部分(文件记录的是 <em>firstDirytOffset</em>), 如果客户端能赶上 <em>dirty</em> 部分, 就  能读到日志所有消息了</li>
<li>清理时 <em>broker</em> 会开线程来清, 开多少 <em>log.cleaner.thread</em> 决定</li>
<li>污浊率决定日志文件清理的优先级, 计算公式 dirtyRatio = dirtyBytes / (cleanBytes + dirtyBytes), 可以通过 <em>log.cleaner.min.cleanable.ratio</em> 控制触发压缩的起始比例</li>
<li><em>__consumer_offsets</em> 也是用日志压缩策略进行保存的</li>
<li>清理算法很简单, 用一个 <em>SkimpyOffsetMap</em> 记录 <em>key</em> 和 <em>offset</em>, 遍历两次 <em>log</em>, 第一次记录最大的 <em>offset</em>, 第二次开始删除</li>
<li>墓碑日志 (<em>key != null &amp;&amp; value == null</em>) 清理时机 = 该日志分段的 <em>lastModifiedTime</em> + <em>deleteHorizonMs</em> (<em>broker</em> 的 <em>log.cleaner.delete.retention.ms</em>, 默认86400000, 即24小时) &lt; <em>clean</em> 区域的 <em>lastModifiedTime</em></li>
<li>为防止 <em>compact</em> 出现碎片，每次 <em>compact</em> 会把多个文件分成一组, 每组文件大小不超过 <em>log.segment.bytes</em></li>
<li>每个日志分组清理后会变成 <em>log.clean</em> 文件, 继续 <em>compact</em> 就变成 <em>log.swap</em>, 最后删除原来日志, <em>log.swap</em> 就去掉 <em>swap</em> 后缀, 完成压缩</li>
</ol>
<p><center></p>
<p><img alt="日志压缩" src="../assets/img/5.4.2.jpg" /></p>
<p></center></p>
<h4 id="55">5.5 磁盘存储<a class="headerlink" href="#55" title="Permanent link">&para;</a></h4>
<blockquote>
<p>讲述 Kafka 在落盘时候的优化</p>
</blockquote>
<h5 id="551">5.5.1 页缓存<a class="headerlink" href="#551" title="Permanent link">&para;</a></h5>
<p>Kafka 使用了大量页缓存, 先把数据写到页缓存, 然后再根据配置 fsync 异步落盘, 落盘可以用 <em>log.flush.interval.messages、log.flush.interval.ms</em> 控制</p>
<h5 id="552_io">5.5.2 磁盘 I/O 流程<a class="headerlink" href="#552_io" title="Permanent link">&para;</a></h5>
<p><center></p>
<p><img alt="磁盘IO流程" src="../assets/img/5.5.2.jpg" /></p>
<p></center></p>
<p>· 写操作：用户调用fwrite把数据写入C库标准IObuffer后就返回，即写操作通常是异步操作；数据写入C库标准IObuffer后，不会立即刷新到磁盘，会将多次小数据量相邻写操作先缓存起来合并，最终调用write函数一次性写入（或者将大块数据分解多次write 调用）页缓存；数据到达页缓存后也不会立即刷新到磁盘，内核有 pdflush 线程在不停地检测脏页，判断是否要写回到磁盘，如果是则发起磁盘I/O请求。</p>
<p>· 读操作：用户调用fread到C库标准IObuffer中读取数据，如果成功则返回，否则继续；到页缓存中读取数据，如果成功则返回，否则继续；发起 I/O 请求，读取数据后缓存buffer和C库标准IObuffer并返回。可以看出，读操作是同步请求。</p>
<p>· I/O请求处理：通用块层根据I/O请求构造一个或多个bio结构并提交给调度层；调度器将 bio 结构进行排序和合并组织成队列且确保读写操作尽可能理想：将一个或多个进程的读操作合并到一起读，将一个或多个进程的写操作合并到一起写，尽可能变随机为顺序（因为随机读写比顺序读写要慢），读必须优先满足，而写也不能等太久。</p>
<p>I/O 调度分以下几种
1. NOOP: 简单的FIFO队列
2. CFQ: 按照I/O请求的地址进行排序, 每个进程单独创建一个队列来管理该进程所产生的请求, 根据时间片去调度，但有可能会饿死
3. DEADLINE: 除了CFQ本身具有的I/O排序队列，DEADLINE额外分别为读I/O和写I/O提供了FIFO队列。读FIFO队列的最大等待时间为500ms，写FIFO队列的最大等待时间为5s, READ &gt; WRITE &gt; CFQ
4. ANTICIPATORY: 在DEADLINE的基础上，为每个读I/O都设置了6ms的等待时间窗口。如果在6ms内OS收到了相邻位置的读I/O请求，就可以立即满足。ANTICIPATORY算法通过增加等待时间来获得更高的性能，假设一个块设备只有一个物理查找磁头（例如一个单独的SATA硬盘），将多个随机的小写入流合并成一个大写入流（相当于将随机读写变顺序读写），通过这个原理来使用读取/写入的延时换取最大的读取/写入吞吐量。适用于大多数环境，特别是读取/写入较多的环境。</p>
<h5 id="553">5.5.3 零拷贝<a class="headerlink" href="#553" title="Permanent link">&para;</a></h5>
<p>对 <em>Linux</em> 操作系统而言，零拷贝技术依赖于底层的 <em>sendfile()</em> 方法实现。对应于 <em>Java</em> 语言，<em>FileChannal.transferTo()</em> 方法的底层实现就是<em>sendfile()</em> 方法</p>
<p><center></p>
<p><img alt="零拷贝" src="../assets/img/5.5.2.jpg" /></p>
<p></center></p>
<h3 id="6">第6章 深入服务端<a class="headerlink" href="#6" title="Permanent link">&para;</a></h3>
<h4 id="61">6.1 协议设计<a class="headerlink" href="#61" title="Permanent link">&para;</a></h4>
<h4 id="62">6.2 时间轮<a class="headerlink" href="#62" title="Permanent link">&para;</a></h4>
<h4 id="63">6.3 延时操作<a class="headerlink" href="#63" title="Permanent link">&para;</a></h4>
<h4 id="64">6.4 控制器<a class="headerlink" href="#64" title="Permanent link">&para;</a></h4>
<h5 id="641">6.4.1 控制器的选举及异常恢复<a class="headerlink" href="#641" title="Permanent link">&para;</a></h5>
<h5 id="642">6.4.2 优雅关闭<a class="headerlink" href="#642" title="Permanent link">&para;</a></h5>
<h4 id="65">6.5 参数解密<a class="headerlink" href="#65" title="Permanent link">&para;</a></h4>
<h5 id="651_brokerid">6.5.1 broker.id<a class="headerlink" href="#651_brokerid" title="Permanent link">&para;</a></h5>
<h5 id="652_bootstrapservers">6.5.2 bootstrap.servers<a class="headerlink" href="#652_bootstrapservers" title="Permanent link">&para;</a></h5>
<h5 id="653">6.5.3 服务端参数列表<a class="headerlink" href="#653" title="Permanent link">&para;</a></h5>
<h3 id="7">第7章 深入客户端<a class="headerlink" href="#7" title="Permanent link">&para;</a></h3>
<h3 id="8">第8章 可靠性探究<a class="headerlink" href="#8" title="Permanent link">&para;</a></h3>
<h3 id="9_kafka">第9章 Kafka应用<a class="headerlink" href="#9_kafka" title="Permanent link">&para;</a></h3>
<h3 id="10_kafka">第10章 Kafka监控<a class="headerlink" href="#10_kafka" title="Permanent link">&para;</a></h3>
<h3 id="11_1">第11章 高级应用<a class="headerlink" href="#11_1" title="Permanent link">&para;</a></h3>
<h3 id="12_kafkaspark">第12章 Kafka与Spark的集成<a class="headerlink" href="#12_kafkaspark" title="Permanent link">&para;</a></h3>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../database/%E9%AB%98%E6%80%A7%E8%83%BDMySQL/" class="btn btn-neutral float-right" title="高性能MySQL-第三版">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>MIT License</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
      <span><a href="../../database/%E9%AB%98%E6%80%A7%E8%83%BDMySQL/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
